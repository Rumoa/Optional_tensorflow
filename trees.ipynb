{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c73d5435-badf-4e60-bcc9-ac658ae0dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fab8c963-0c36-47a6-8350-c96203f791ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"krkopt.data\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f26ea07c-fb45-496e-82ef-c918e92a0626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28056 entries, 0 to 28055\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       28056 non-null  object\n",
      " 1   1       28056 non-null  int64 \n",
      " 2   2       28056 non-null  object\n",
      " 3   3       28056 non-null  int64 \n",
      " 4   4       28056 non-null  object\n",
      " 5   5       28056 non-null  int64 \n",
      " 6   6       28056 non-null  object\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2e53c1b4-75dc-4d87-bb5b-995d9fe9c90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [\"wkc\", \"wkr\", \"wrc\", \"wrr\", \"bkc\", \"bkr\", \"opt rank\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ddd08383-af47-4ecc-a74c-60dada373956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[[\"wkc\", \"wrc\", \"bkc\", \"opt rank\"]] = data[[\"wkc\", \"wrc\", \"bkc\", \"opt rank\"]].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2a707234-0396-43db-9377-a1dc4cd750a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28056 entries, 0 to 28055\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   wkc       28056 non-null  object\n",
      " 1   wkr       28056 non-null  int64 \n",
      " 2   wrc       28056 non-null  object\n",
      " 3   wrr       28056 non-null  int64 \n",
      " 4   bkc       28056 non-null  object\n",
      " 5   bkr       28056 non-null  int64 \n",
      " 6   opt rank  28056 non-null  object\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d8e43947-f0d9-4bf5-a867-c7b8b02460a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = data.iloc[:, 0:6]\n",
    "# y = data['opt rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5f0361b0-aefa-4e48-b84a-3cd8c556e100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "50dae2d1-182c-4019-a45f-69d88c7060f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2792257a-fe15-45d2-b360-2751fe5a91e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22444, 7), (5612, 7))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "27a457a7-8025-4055-8ff3-809112836c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6288590b-2c80-4804-8274-c07cb0989946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4fd4b2d4-1e82-44ba-a3a2-b41c5599ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_decision_forests as tfdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9c25ac67-9212-4fde-8baf-65f95a7170d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.20.2'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bc1047b2-2ac9-4704-b835-d0c482694838",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tfdf.keras.pd_dataframe_to_tf_dataset(train, label=\"opt rank\")\n",
    "test = tfdf.keras.pd_dataframe_to_tf_dataset(test, label=\"opt rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c49dae40-52e6-4804-977c-99cc955e7c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ({wkc: (None,), wkr: (None,), wrc: (None,), wrr: (None,), bkc: (None,), bkr: (None,)}, (None,)), types: ({wkc: tf.string, wkr: tf.int64, wrc: tf.string, wrr: tf.int64, bkc: tf.string, bkr: tf.int64}, tf.int64)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6bc4de29-2c41-4be6-a6ae-ae418247a8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tfdf.keras.RandomForestModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "84c39d26-3ede-4c00-a718-ff50b16ce887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 0s 803us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9e6c7e9490>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7d3b5a6e-5500-4254-ad6b-e38c66f4cded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"random_forest_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Total params: 1\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "Type: \"RANDOM_FOREST\"\n",
      "Task: CLASSIFICATION\n",
      "Label: \"__LABEL\"\n",
      "\n",
      "Input Features (6):\n",
      "\tbkc\n",
      "\tbkr\n",
      "\twkc\n",
      "\twkr\n",
      "\twrc\n",
      "\twrr\n",
      "\n",
      "No weights\n",
      "\n",
      "Variable Importance: NUM_NODES:\n",
      "    1. \"wrr\" 215559.000000 ################\n",
      "    2. \"wrc\" 167230.000000 ############\n",
      "    3. \"bkr\" 119192.000000 ########\n",
      "    4. \"bkc\" 112909.000000 #######\n",
      "    5. \"wkc\" 51481.000000 ##\n",
      "    6. \"wkr\" 21590.000000 \n",
      "\n",
      "Variable Importance: NUM_AS_ROOT:\n",
      "    1. \"bkr\" 197.000000 ################\n",
      "    2. \"wkr\" 85.000000 ######\n",
      "    3. \"wkc\" 14.000000 \n",
      "    4. \"bkc\"  4.000000 \n",
      "\n",
      "Variable Importance: SUM_SCORE:\n",
      "    1. \"wrr\" 2935321.383898 ################\n",
      "    2. \"wrc\" 2826048.633256 ##############\n",
      "    3. \"bkr\" 2720744.952189 #############\n",
      "    4. \"bkc\" 2522831.245298 ###########\n",
      "    5. \"wkr\" 1705032.820704 ###\n",
      "    6. \"wkc\" 1365061.463163 \n",
      "\n",
      "Variable Importance: MEAN_MIN_DEPTH:\n",
      "    1. \"__LABEL\" 12.355201 ################\n",
      "    2.     \"wrr\"  7.181162 #########\n",
      "    3.     \"wrc\"  5.554057 ######\n",
      "    4.     \"wkc\"  4.474268 #####\n",
      "    5.     \"wkr\"  2.203379 ##\n",
      "    6.     \"bkc\"  2.129502 ##\n",
      "    7.     \"bkr\"  0.504474 \n",
      "\n",
      "\n",
      "\n",
      "Winner take all: true\n",
      "Out-of-bag evaluation: accuracy:0.761941 logloss:0.765058\n",
      "Number of trees: 300\n",
      "Total number of nodes: 1376222\n",
      "\n",
      "Number of nodes by tree:\n",
      "Count: 300 Average: 4587.41 StdDev: 81.3084\n",
      "Min: 4379 Max: 4903 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 4379, 4405)  4   1.33%   1.33% #\n",
      "[ 4405, 4431)  3   1.00%   2.33% #\n",
      "[ 4431, 4457)  9   3.00%   5.33% ##\n",
      "[ 4457, 4484) 12   4.00%   9.33% ###\n",
      "[ 4484, 4510) 21   7.00%  16.33% #####\n",
      "[ 4510, 4536) 39  13.00%  29.33% ##########\n",
      "[ 4536, 4562) 31  10.33%  39.67% ########\n",
      "[ 4562, 4589) 34  11.33%  51.00% #########\n",
      "[ 4589, 4615) 35  11.67%  62.67% #########\n",
      "[ 4615, 4641) 32  10.67%  73.33% ########\n",
      "[ 4641, 4667) 26   8.67%  82.00% #######\n",
      "[ 4667, 4694) 24   8.00%  90.00% ######\n",
      "[ 4694, 4720) 17   5.67%  95.67% ####\n",
      "[ 4720, 4746)  8   2.67%  98.33% ##\n",
      "[ 4746, 4772)  4   1.33%  99.67% #\n",
      "[ 4772, 4799)  0   0.00%  99.67%\n",
      "[ 4799, 4825)  0   0.00%  99.67%\n",
      "[ 4825, 4851)  0   0.00%  99.67%\n",
      "[ 4851, 4877)  0   0.00%  99.67%\n",
      "[ 4877, 4903]  1   0.33% 100.00%\n",
      "\n",
      "Depth by leafs:\n",
      "Count: 688261 Average: 12.355 StdDev: 1.81216\n",
      "Min: 5 Max: 15 Ignored: 0\n",
      "----------------------------------------------\n",
      "[  5,  6)      3   0.00%   0.00%\n",
      "[  6,  7)    225   0.03%   0.03%\n",
      "[  7,  8)   2043   0.30%   0.33%\n",
      "[  8,  9)  10148   1.47%   1.80% #\n",
      "[  9, 10)  32115   4.67%   6.47% ##\n",
      "[ 10, 11)  69600  10.11%  16.58% #####\n",
      "[ 11, 12) 108357  15.74%  32.33% ########\n",
      "[ 12, 13) 130304  18.93%  51.26% ##########\n",
      "[ 13, 14) 130043  18.89%  70.15% ##########\n",
      "[ 14, 15) 105877  15.38%  85.54% ########\n",
      "[ 15, 15]  99546  14.46% 100.00% ########\n",
      "\n",
      "Number of training obs by leaf:\n",
      "Count: 688261 Average: 9.78292 StdDev: 10.2775\n",
      "Min: 5 Max: 251 Ignored: 0\n",
      "----------------------------------------------\n",
      "[   5,  17) 624679  90.76%  90.76% ##########\n",
      "[  17,  29)  38624   5.61%  96.37% #\n",
      "[  29,  42)  13538   1.97%  98.34%\n",
      "[  42,  54)   5101   0.74%  99.08%\n",
      "[  54,  66)   2475   0.36%  99.44%\n",
      "[  66,  79)   1299   0.19%  99.63%\n",
      "[  79,  91)    673   0.10%  99.73%\n",
      "[  91, 103)    483   0.07%  99.80%\n",
      "[ 103, 116)    331   0.05%  99.85%\n",
      "[ 116, 128)    216   0.03%  99.88%\n",
      "[ 128, 140)    188   0.03%  99.90%\n",
      "[ 140, 153)    154   0.02%  99.93%\n",
      "[ 153, 165)    126   0.02%  99.95%\n",
      "[ 165, 177)    101   0.01%  99.96%\n",
      "[ 177, 190)     91   0.01%  99.97%\n",
      "[ 190, 202)     71   0.01%  99.98%\n",
      "[ 202, 214)     77   0.01% 100.00%\n",
      "[ 214, 227)     28   0.00% 100.00%\n",
      "[ 227, 239)      4   0.00% 100.00%\n",
      "[ 239, 251]      2   0.00% 100.00%\n",
      "\n",
      "Attribute in nodes:\n",
      "\t215559 : wrr [NUMERICAL]\n",
      "\t167230 : wrc [CATEGORICAL]\n",
      "\t119192 : bkr [NUMERICAL]\n",
      "\t112909 : bkc [CATEGORICAL]\n",
      "\t51481 : wkc [CATEGORICAL]\n",
      "\t21590 : wkr [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 0:\n",
      "\t197 : bkr [NUMERICAL]\n",
      "\t85 : wkr [NUMERICAL]\n",
      "\t14 : wkc [CATEGORICAL]\n",
      "\t4 : bkc [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 1:\n",
      "\t331 : bkr [NUMERICAL]\n",
      "\t230 : wkr [NUMERICAL]\n",
      "\t172 : bkc [CATEGORICAL]\n",
      "\t158 : wkc [CATEGORICAL]\n",
      "\t9 : wrr [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 2:\n",
      "\t649 : bkc [CATEGORICAL]\n",
      "\t490 : bkr [NUMERICAL]\n",
      "\t457 : wkr [NUMERICAL]\n",
      "\t377 : wkc [CATEGORICAL]\n",
      "\t116 : wrr [NUMERICAL]\n",
      "\t11 : wrc [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 3:\n",
      "\t1187 : bkc [CATEGORICAL]\n",
      "\t952 : wkr [NUMERICAL]\n",
      "\t856 : bkr [NUMERICAL]\n",
      "\t849 : wkc [CATEGORICAL]\n",
      "\t442 : wrr [NUMERICAL]\n",
      "\t214 : wrc [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 5:\n",
      "\t4260 : wrc [CATEGORICAL]\n",
      "\t3594 : bkc [CATEGORICAL]\n",
      "\t3097 : bkr [NUMERICAL]\n",
      "\t2835 : wrr [NUMERICAL]\n",
      "\t2827 : wkc [CATEGORICAL]\n",
      "\t2284 : wkr [NUMERICAL]\n",
      "\n",
      "Condition type in nodes:\n",
      "\t356341 : HigherCondition\n",
      "\t331620 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 0:\n",
      "\t282 : HigherCondition\n",
      "\t18 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 1:\n",
      "\t570 : HigherCondition\n",
      "\t330 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 2:\n",
      "\t1063 : HigherCondition\n",
      "\t1037 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 3:\n",
      "\t2250 : ContainsBitmapCondition\n",
      "\t2250 : HigherCondition\n",
      "Condition type in nodes with depth <= 5:\n",
      "\t10681 : ContainsBitmapCondition\n",
      "\t8216 : HigherCondition\n",
      "\n",
      "Training OOB:\n",
      "\ttrees: 1, Out-of-bag evaluation: accuracy:0.669493 logloss:11.9127\n",
      "\ttrees: 11, Out-of-bag evaluation: accuracy:0.700188 logloss:4.81498\n",
      "\ttrees: 21, Out-of-bag evaluation: accuracy:0.730473 logloss:2.62349\n",
      "\ttrees: 31, Out-of-bag evaluation: accuracy:0.738594 logloss:1.92955\n",
      "\ttrees: 41, Out-of-bag evaluation: accuracy:0.744475 logloss:1.59927\n",
      "\ttrees: 51, Out-of-bag evaluation: accuracy:0.748351 logloss:1.39606\n",
      "\ttrees: 61, Out-of-bag evaluation: accuracy:0.749644 logloss:1.27159\n",
      "\ttrees: 71, Out-of-bag evaluation: accuracy:0.753743 logloss:1.16864\n",
      "\ttrees: 81, Out-of-bag evaluation: accuracy:0.755926 logloss:1.11447\n",
      "\ttrees: 91, Out-of-bag evaluation: accuracy:0.755837 logloss:1.06734\n",
      "\ttrees: 101, Out-of-bag evaluation: accuracy:0.756906 logloss:1.02295\n",
      "\ttrees: 111, Out-of-bag evaluation: accuracy:0.75802 logloss:0.978422\n",
      "\ttrees: 121, Out-of-bag evaluation: accuracy:0.759268 logloss:0.939011\n",
      "\ttrees: 131, Out-of-bag evaluation: accuracy:0.758154 logloss:0.919636\n",
      "\ttrees: 141, Out-of-bag evaluation: accuracy:0.758733 logloss:0.910482\n",
      "\ttrees: 151, Out-of-bag evaluation: accuracy:0.759847 logloss:0.890865\n",
      "\ttrees: 161, Out-of-bag evaluation: accuracy:0.761272 logloss:0.873203\n",
      "\ttrees: 171, Out-of-bag evaluation: accuracy:0.761406 logloss:0.864841\n",
      "\ttrees: 181, Out-of-bag evaluation: accuracy:0.760471 logloss:0.850008\n",
      "\ttrees: 191, Out-of-bag evaluation: accuracy:0.759357 logloss:0.839576\n",
      "\ttrees: 201, Out-of-bag evaluation: accuracy:0.760649 logloss:0.829186\n",
      "\ttrees: 211, Out-of-bag evaluation: accuracy:0.761718 logloss:0.816521\n",
      "\ttrees: 221, Out-of-bag evaluation: accuracy:0.761139 logloss:0.810196\n",
      "\ttrees: 231, Out-of-bag evaluation: accuracy:0.760916 logloss:0.804829\n",
      "\ttrees: 241, Out-of-bag evaluation: accuracy:0.761763 logloss:0.801746\n",
      "\ttrees: 251, Out-of-bag evaluation: accuracy:0.761629 logloss:0.794905\n",
      "\ttrees: 261, Out-of-bag evaluation: accuracy:0.761228 logloss:0.78926\n",
      "\ttrees: 271, Out-of-bag evaluation: accuracy:0.761451 logloss:0.783798\n",
      "\ttrees: 281, Out-of-bag evaluation: accuracy:0.761139 logloss:0.776677\n",
      "\ttrees: 291, Out-of-bag evaluation: accuracy:0.761272 logloss:0.765258\n",
      "\ttrees: 300, Out-of-bag evaluation: accuracy:0.761941 logloss:0.765058\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e2168539-b715-4f85-83d4-e37bd3b74213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 1s 8ms/step - loss: 0.0000e+00 - accuracy: 0.7803\n",
      "[0.0, 0.7802922129631042]\n"
     ]
    }
   ],
   "source": [
    "model.compile(metrics=[\"accuracy\"])\n",
    "print(model.evaluate(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aa3617f3-b88d-4d25-b55c-692225ca49f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0d09f6b4-bfcc-48db-b932-a4cd1d2ed20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script src=\"https://d3js.org/d3.v6.min.js\"></script>\n",
       "<div id=\"tree_plot_eb19abc8a79a46169f3381bcc46e41af\"></div>\n",
       "<script>\n",
       "/*\n",
       " * Copyright 2021 Google LLC.\n",
       " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       " * you may not use this file except in compliance with the License.\n",
       " * You may obtain a copy of the License at\n",
       " *\n",
       " *     https://www.apache.org/licenses/LICENSE-2.0\n",
       " *\n",
       " * Unless required by applicable law or agreed to in writing, software\n",
       " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       " * See the License for the specific language governing permissions and\n",
       " * limitations under the License.\n",
       " */\n",
       "\n",
       "/**\n",
       " *  Plotting of decision trees generated by TF-DF.\n",
       " *\n",
       " *  A tree is a recursive structure of node objects.\n",
       " *  A node contains one or more of the following components:\n",
       " *\n",
       " *    - A value: Representing the output of the node. If the node is not a leaf,\n",
       " *      the value is only present for analysis i.e. it is not used for\n",
       " *      predictions.\n",
       " *\n",
       " *    - A condition : For non-leaf nodes, the condition (also known as split)\n",
       " *      defines a binary test to branch to the positive or negative child.\n",
       " *\n",
       " *    - An explanation: Generally a plot showing the relation between the label\n",
       " *      and the condition to give insights about the effect of the condition.\n",
       " *\n",
       " *    - Two children : For non-leaf nodes, the children nodes. The first\n",
       " *      children (i.e. \"node.children[0]\") is the negative children (drawn in\n",
       " *      red). The second children is the positive one (drawn in green).\n",
       " *\n",
       " */\n",
       "\n",
       "/**\n",
       " * Generate the default options object.\n",
       " * @return {!options} Default configuration options.\n",
       " */\n",
       "function build_default_options() {\n",
       "  // Display configuration.\n",
       "  // Note: Dimensions are expressed in pixels.\n",
       "  return {\n",
       "    // Margin around the entire plot.\n",
       "    margin: 10,\n",
       "\n",
       "    // Size of a tree node.\n",
       "    node_x_size: 160,\n",
       "    node_y_size: 12 * 2 + 4,\n",
       "\n",
       "    // Space between tree nodes.\n",
       "    node_x_offset: 160 + 20,\n",
       "    node_y_offset: 12 * 2 + 4 + 5,\n",
       "\n",
       "    // Text size.\n",
       "    font_size: 10,\n",
       "\n",
       "    // Rounding effect of the edges.\n",
       "    // This value is the distance (in pixel) of the Bezier control anchor from\n",
       "    // the source point.\n",
       "    edge_rounding: 20,\n",
       "\n",
       "    // Padding inside nodes.\n",
       "    node_padding: 2,\n",
       "\n",
       "    // Show a bb box around the plot. For debug only.\n",
       "    show_plot_bounding_box: false,\n",
       "  };\n",
       "}\n",
       "\n",
       "/**\n",
       " * Plots a single decision tree into a DOM element.\n",
       " * @param {!options} options Dictionary of configurations.\n",
       " * @param {!tree} raw_tree Recursive tree structure.\n",
       " * @param {string} canvas_id Id of the output dom element.\n",
       " */\n",
       "function display_tree(options, raw_tree, canvas_id) {\n",
       "  // Get default options.\n",
       "  const default_options = build_default_options();\n",
       "  Object.keys(default_options).forEach(function(key) {\n",
       "    if (!(key in options)) {\n",
       "      options[key] = default_options[key];\n",
       "    }\n",
       "  });\n",
       "\n",
       "  console.log(options);\n",
       "\n",
       "  // Determine the node placement.\n",
       "  const tree_struct = d3.tree().nodeSize(\n",
       "      [options.node_y_offset, options.node_x_offset])(d3.hierarchy(raw_tree));\n",
       "\n",
       "  // Boundaries of the node placement.\n",
       "  let x_min = Infinity;\n",
       "  let x_max = -x_min;\n",
       "  let y_min = Infinity;\n",
       "  let y_max = -x_min;\n",
       "\n",
       "  tree_struct.each(d => {\n",
       "    if (d.x > x_max) x_max = d.x;\n",
       "    if (d.x < x_min) x_min = d.x;\n",
       "    if (d.y > y_max) y_max = d.y;\n",
       "    if (d.y < y_min) y_min = d.y;\n",
       "  });\n",
       "\n",
       "  // Size of the plot.\n",
       "  const width = y_max - y_min + options.node_x_size + options.margin * 2;\n",
       "  const height = x_max - x_min + options.node_y_size + options.margin * 2 +\n",
       "      options.node_y_offset - options.node_y_size;\n",
       "\n",
       "  const plot = d3.select(canvas_id);\n",
       "\n",
       "  // Tool tip\n",
       "  options.tooltip = plot.append('div')\n",
       "                        .attr('width', 100)\n",
       "                        .attr('height', 100)\n",
       "                        .style('padding', '4px')\n",
       "                        .style('background', '#fff')\n",
       "                        .style('box-shadow', '4px 4px 0px rgba(0,0,0,0.1)')\n",
       "                        .style('border', '1px solid black')\n",
       "                        .style('font-family', 'sans-serif')\n",
       "                        .style('font-size', options.font_size)\n",
       "                        .style('position', 'absolute')\n",
       "                        .style('z-index', '10')\n",
       "                        .attr('pointer-events', 'none')\n",
       "                        .style('display', 'none');\n",
       "\n",
       "  // Create canvas\n",
       "  const svg = plot.append('svg').attr('width', width).attr('height', height);\n",
       "  const graph =\n",
       "      svg.style('overflow', 'visible')\n",
       "          .append('g')\n",
       "          .attr('font-family', 'sans-serif')\n",
       "          .attr('font-size', options.font_size)\n",
       "          .attr(\n",
       "              'transform',\n",
       "              () => `translate(${options.margin},${\n",
       "                  - x_min + options.node_y_offset / 2 + options.margin})`);\n",
       "\n",
       "  // Plot bounding box.\n",
       "  if (options.show_plot_bounding_box) {\n",
       "    svg.append('rect')\n",
       "        .attr('width', width)\n",
       "        .attr('height', height)\n",
       "        .attr('fill', 'none')\n",
       "        .attr('stroke-width', 1.0)\n",
       "        .attr('stroke', 'black');\n",
       "  }\n",
       "\n",
       "  // Draw the edges.\n",
       "  display_edges(options, graph, tree_struct);\n",
       "\n",
       "  // Draw the nodes.\n",
       "  display_nodes(options, graph, tree_struct);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Draw the nodes of the tree.\n",
       " * @param {!options} options Dictionary of configurations.\n",
       " * @param {!graph} graph D3 search handle containing the graph.\n",
       " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
       " *     data, etc.).\n",
       " */\n",
       "function display_nodes(options, graph, tree_struct) {\n",
       "  const nodes = graph.append('g')\n",
       "                    .selectAll('g')\n",
       "                    .data(tree_struct.descendants())\n",
       "                    .join('g')\n",
       "                    .attr('transform', d => `translate(${d.y},${d.x})`);\n",
       "\n",
       "  nodes.append('rect')\n",
       "      .attr('x', 0.5)\n",
       "      .attr('y', 0.5)\n",
       "      .attr('width', options.node_x_size)\n",
       "      .attr('height', options.node_y_size)\n",
       "      .attr('stroke', 'lightgrey')\n",
       "      .attr('stroke-width', 1)\n",
       "      .attr('fill', 'white')\n",
       "      .attr('y', -options.node_y_size / 2);\n",
       "\n",
       "  // Brackets on the right of condition nodes without children.\n",
       "  non_leaf_node_without_children =\n",
       "      nodes.filter(node => node.data.condition != null && node.children == null)\n",
       "          .append('g')\n",
       "          .attr('transform', `translate(${options.node_x_size},0)`);\n",
       "\n",
       "  non_leaf_node_without_children.append('path')\n",
       "      .attr('d', 'M0,0 C 10,0 0,10 10,10')\n",
       "      .attr('fill', 'none')\n",
       "      .attr('stroke-width', 1.0)\n",
       "      .attr('stroke', '#F00');\n",
       "\n",
       "  non_leaf_node_without_children.append('path')\n",
       "      .attr('d', 'M0,0 C 10,0 0,-10 10,-10')\n",
       "      .attr('fill', 'none')\n",
       "      .attr('stroke-width', 1.0)\n",
       "      .attr('stroke', '#0F0');\n",
       "\n",
       "  const node_content = nodes.append('g').attr(\n",
       "      'transform',\n",
       "      `translate(0,${options.node_padding - options.node_y_size / 2})`);\n",
       "\n",
       "  node_content.append(node => create_node_element(options, node));\n",
       "}\n",
       "\n",
       "/**\n",
       " * Creates the D3 content for a single node.\n",
       " * @param {!options} options Dictionary of configurations.\n",
       " * @param {!node} node Node to draw.\n",
       " * @return {!d3} D3 content.\n",
       " */\n",
       "function create_node_element(options, node) {\n",
       "  // Output accumulator.\n",
       "  let output = {\n",
       "    // Content to draw.\n",
       "    content: d3.create('svg:g'),\n",
       "    // Vertical offset to the next element to draw.\n",
       "    vertical_offset: 0\n",
       "  };\n",
       "\n",
       "  // Conditions.\n",
       "  if (node.data.condition != null) {\n",
       "    display_condition(options, node.data.condition, output);\n",
       "  }\n",
       "\n",
       "  // Values.\n",
       "  if (node.data.value != null) {\n",
       "    display_value(options, node.data.value, output);\n",
       "  }\n",
       "\n",
       "  // Explanations.\n",
       "  if (node.data.explanation != null) {\n",
       "    display_explanation(options, node.data.explanation, output);\n",
       "  }\n",
       "\n",
       "  return output.content.node();\n",
       "}\n",
       "\n",
       "\n",
       "/**\n",
       " * Adds a single line of text inside of a node.\n",
       " * @param {!options} options Dictionary of configurations.\n",
       " * @param {string} text Text to display.\n",
       " * @param {!output} output Output display accumulator.\n",
       " */\n",
       "function display_node_text(options, text, output) {\n",
       "  output.content.append('text')\n",
       "      .attr('x', options.node_padding)\n",
       "      .attr('y', output.vertical_offset)\n",
       "      .attr('alignment-baseline', 'hanging')\n",
       "      .text(text);\n",
       "  output.vertical_offset += 10;\n",
       "}\n",
       "\n",
       "/**\n",
       " * Adds a single line of text inside of a node with a tooltip.\n",
       " * @param {!options} options Dictionary of configurations.\n",
       " * @param {string} text Text to display.\n",
       " * @param {string} tooltip Text in the Tooltip.\n",
       " * @param {!output} output Output display accumulator.\n",
       " */\n",
       "function display_node_text_with_tooltip(options, text, tooltip, output) {\n",
       "  const item = output.content.append('text')\n",
       "                   .attr('x', options.node_padding)\n",
       "                   .attr('alignment-baseline', 'hanging')\n",
       "                   .text(text);\n",
       "\n",
       "  add_tooltip(options, item, () => tooltip);\n",
       "  output.vertical_offset += 10;\n",
       "}\n",
       "\n",
       "/**\n",
       " * Adds a tooltip to a dom element.\n",
       " * @param {!options} options Dictionary of configurations.\n",
       " * @param {!dom} target Dom element to equip with a tooltip.\n",
       " * @param {!func} get_content Generates the html content of the tooltip.\n",
       " */\n",
       "function add_tooltip(options, target, get_content) {\n",
       "  function show(d) {\n",
       "    options.tooltip.style('display', 'block');\n",
       "    options.tooltip.html(get_content());\n",
       "  }\n",
       "\n",
       "  function hide(d) {\n",
       "    options.tooltip.style('display', 'none');\n",
       "  }\n",
       "\n",
       "  function move(d) {\n",
       "    options.tooltip.style('display', 'block');\n",
       "    options.tooltip.style('left', (d.pageX + 5) + 'px');\n",
       "    options.tooltip.style('top', d.pageY + 'px');\n",
       "  }\n",
       "\n",
       "  target.on('mouseover', show);\n",
       "  target.on('mouseout', hide);\n",
       "  target.on('mousemove', move);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Adds a condition inside of a node.\n",
       " * @param {!options} options Dictionary of configurations.\n",
       " * @param {!condition} condition Condition to display.\n",
       " * @param {!output} output Output display accumulator.\n",
       " */\n",
       "function display_condition(options, condition, output) {\n",
       "  threshold_format = d3.format('r');\n",
       "\n",
       "  if (condition.type === 'IS_MISSING') {\n",
       "    display_node_text(options, `${condition.attribute} is missing`, output);\n",
       "    return;\n",
       "  }\n",
       "\n",
       "  if (condition.type === 'IS_TRUE') {\n",
       "    display_node_text(options, `${condition.attribute} is true`, output);\n",
       "    return;\n",
       "  }\n",
       "\n",
       "  if (condition.type === 'NUMERICAL_IS_HIGHER_THAN') {\n",
       "    format = d3.format('r');\n",
       "    display_node_text(\n",
       "        options,\n",
       "        `${condition.attribute} >= ${threshold_format(condition.threshold)}`,\n",
       "        output);\n",
       "    return;\n",
       "  }\n",
       "\n",
       "  if (condition.type === 'CATEGORICAL_IS_IN') {\n",
       "    display_node_text_with_tooltip(\n",
       "        options, `${condition.attribute} in [...]`,\n",
       "        `${condition.attribute} in [${condition.mask}]`, output);\n",
       "    return;\n",
       "  }\n",
       "\n",
       "  if (condition.type === 'CATEGORICAL_SET_CONTAINS') {\n",
       "    display_node_text_with_tooltip(\n",
       "        options, `${condition.attribute} intersect [...]`,\n",
       "        `${condition.attribute} intersect [${condition.mask}]`, output);\n",
       "    return;\n",
       "  }\n",
       "\n",
       "  if (condition.type === 'NUMERICAL_SPARSE_OBLIQUE') {\n",
       "    display_node_text_with_tooltip(\n",
       "        options, `Sparse oblique split...`,\n",
       "        `[${condition.attributes}]*[${condition.weights}]>=${\n",
       "            threshold_format(condition.threshold)}`,\n",
       "        output);\n",
       "    return;\n",
       "  }\n",
       "\n",
       "  display_node_text(\n",
       "      options, `Non supported condition ${condition.type}`, output);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Adds a value inside of a node.\n",
       " * @param {!options} options Dictionary of configurations.\n",
       " * @param {!value} value Value to display.\n",
       " * @param {!output} output Output display accumulator.\n",
       " */\n",
       "function display_value(options, value, output) {\n",
       "  if (value.type === 'PROBABILITY') {\n",
       "    const left_margin = 0;\n",
       "    const right_margin = 50;\n",
       "    const plot_width = options.node_x_size - options.node_padding * 2 -\n",
       "        left_margin - right_margin;\n",
       "\n",
       "    let cusum = Array.from(d3.cumsum(value.distribution));\n",
       "    cusum.unshift(0);\n",
       "    const distribution_plot = output.content.append('g').attr(\n",
       "        'transform', `translate(0,${output.vertical_offset + 0.5})`);\n",
       "\n",
       "    distribution_plot.selectAll('rect')\n",
       "        .data(value.distribution)\n",
       "        .join('rect')\n",
       "        .attr('height', 10)\n",
       "        .attr(\n",
       "            'x',\n",
       "            (d, i) =>\n",
       "                (cusum[i] * plot_width + left_margin + options.node_padding))\n",
       "        .attr('width', (d, i) => d * plot_width)\n",
       "        .style('fill', (d, i) => d3.schemeSet1[i]);\n",
       "\n",
       "    const num_examples =\n",
       "        output.content.append('g')\n",
       "            .attr('transform', `translate(0,${output.vertical_offset})`)\n",
       "            .append('text')\n",
       "            .attr('x', options.node_x_size - options.node_padding)\n",
       "            .attr('alignment-baseline', 'hanging')\n",
       "            .attr('text-anchor', 'end')\n",
       "            .text(`(${value.num_examples})`);\n",
       "\n",
       "    const distribution_details = d3.create('ul');\n",
       "    distribution_details.selectAll('li')\n",
       "        .data(value.distribution)\n",
       "        .join('li')\n",
       "        .append('span')\n",
       "        .text(\n",
       "            (d, i) =>\n",
       "                'class ' + i + ': ' + d3.format('.3%')(value.distribution[i]));\n",
       "\n",
       "    add_tooltip(options, distribution_plot, () => distribution_details.html());\n",
       "    add_tooltip(options, num_examples, () => 'Number of examples');\n",
       "\n",
       "    output.vertical_offset += 10;\n",
       "    return;\n",
       "  }\n",
       "\n",
       "  if (value.type === 'REGRESSION') {\n",
       "    display_node_text(\n",
       "        options,\n",
       "        'value: ' + d3.format('r')(value.value) + ` (${value.num_examples})`,\n",
       "        output);\n",
       "    return;\n",
       "  }\n",
       "\n",
       "  display_node_text(options, `Non supported value ${value.type}`, output);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Adds an explanation inside of a node.\n",
       " * @param {!options} options Dictionary of configurations.\n",
       " * @param {!explanation} explanation Explanation to display.\n",
       " * @param {!output} output Output display accumulator.\n",
       " */\n",
       "function display_explanation(options, explanation, output) {\n",
       "  // Margin before the explanation.\n",
       "  output.vertical_offset += 10;\n",
       "\n",
       "  display_node_text(\n",
       "      options, `Non supported explanation ${explanation.type}`, output);\n",
       "}\n",
       "\n",
       "\n",
       "/**\n",
       " * Draw the edges of the tree.\n",
       " * @param {!options} options Dictionary of configurations.\n",
       " * @param {!graph} graph D3 search handle containing the graph.\n",
       " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
       " *     data, etc.).\n",
       " */\n",
       "function display_edges(options, graph, tree_struct) {\n",
       "  // Draw an edge between a parent and a child node with a bezier.\n",
       "  function draw_single_edge(d) {\n",
       "    return 'M' + (d.source.y + options.node_x_size) + ',' + d.source.x + ' C' +\n",
       "        (d.source.y + options.node_x_size + options.edge_rounding) + ',' +\n",
       "        d.source.x + ' ' + (d.target.y - options.edge_rounding) + ',' +\n",
       "        d.target.x + ' ' + d.target.y + ',' + d.target.x;\n",
       "  }\n",
       "\n",
       "  graph.append('g')\n",
       "      .attr('fill', 'none')\n",
       "      .attr('stroke-width', 1.2)\n",
       "      .selectAll('path')\n",
       "      .data(tree_struct.links())\n",
       "      .join('path')\n",
       "      .attr('d', draw_single_edge)\n",
       "      .attr(\n",
       "          'stroke', d => (d.target === d.source.children[0]) ? '#0F0' : '#F00');\n",
       "}\n",
       "\n",
       "display_tree({}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.10100695063268579, 0.05003564427018357, 0.10345749420780609, 0.07467474603457494, 0.015549812867581536, 0.007262520049901978, 0.15558723935127428, 0.06407057565496346, 0.0027178756014970594, 0.023346996970237035, 0.021342006772411336, 0.013188379967920157, 0.06999643557298164, 0.1552307966494386, 0.003074318303332739, 0.12965603279272858, 0.008821956870433079, 0.0009802174300481198], \"num_examples\": 22444.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"wkr\", \"threshold\": 2.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.08894445436685122, 0.11377031612787998, 0.16342203964993748, 0.0, 0.03304161457403108, 0.009465976067154849, 0.002679049830326844, 0.14181103768530096, 0.0028576531523486336, 0.0550098231827112, 0.03750669762457582, 0.0, 0.11448472941596714, 0.046615467047687084, 0.00928737274513306, 0.15895695659939274, 0.020360778710484015, 0.001786033220217896], \"num_examples\": 5599.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"wkr\", \"threshold\": 3.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.10352264557872035, 0.20776419841840402, 0.15025161754133717, 0.0, 0.012221423436376708, 0.007189072609633357, 0.0, 0.27102803738317754, 0.0, 0.06613946800862688, 0.025880661394680086, 0.0, 0.12293314162473042, 0.0, 0.0035945363048166786, 0.029475197699496764, 0.0, 0.0], \"num_examples\": 1391.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"bkr\", \"threshold\": 2.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.1037463976945245, 0.021613832853025938, 0.29394812680115273, 0.0, 0.008645533141210375, 0.0, 0.0, 0.33429394812680113, 0.0, 0.021613832853025938, 0.010086455331412104, 0.0, 0.14697406340057637, 0.0, 0.0, 0.059077809798270896, 0.0, 0.0], \"num_examples\": 694.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"bkc\", \"mask\": [\"g\", \"f\"]}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.10329985652797705, 0.3931133428981349, 0.007173601147776184, 0.0, 0.015781922525107604, 0.014347202295552367, 0.0, 0.20803443328550933, 0.0, 0.11047345767575323, 0.04160688665710186, 0.0, 0.09899569583931134, 0.0, 0.007173601147776184, 0.0, 0.0, 0.0], \"num_examples\": 697.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"bkc\", \"mask\": [\"g\", \"f\", \"e\"]}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0841254752851711, 0.08269961977186312, 0.16777566539923955, 0.0, 0.039923954372623575, 0.010218631178707225, 0.003564638783269962, 0.09909695817490494, 0.0038022813688212928, 0.051330798479087454, 0.04134980988593156, 0.0, 0.11169201520912547, 0.06202471482889734, 0.011169201520912548, 0.20175855513307986, 0.02709125475285171, 0.002376425855513308], \"num_examples\": 4208.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"bkr\", \"threshold\": 2.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.09382382720215997, 0.03779952750590618, 0.21903476206547418, 0.0, 0.00911238609517381, 0.0, 0.005062436719541006, 0.10023624704691192, 0.0, 0.042524468444144446, 0.01181235234559568, 0.0, 0.11373607829902126, 0.08538643266959163, 0.0, 0.28147148160647995, 0.0, 0.0], \"num_examples\": 2963.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"bkc\", \"mask\": [\"g\", \"f\", \"e\", \"d\", \"c\"]}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.06104417670682731, 0.1895582329317269, 0.04578313253012048, 0.0, 0.11325301204819277, 0.03453815261044177, 0.0, 0.0963855421686747, 0.01285140562248996, 0.07228915662650602, 0.11164658634538152, 0.0, 0.10682730923694779, 0.00642570281124498, 0.03775100401606426, 0.012048192771084338, 0.09156626506024096, 0.008032128514056224], \"num_examples\": 1245.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"wkc\", \"mask\": [\"d\"]}}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.10501632531908578, 0.028851291184327693, 0.08352626892252894, 0.09949539922825765, 0.009735826654793707, 0.006530127634312852, 0.2064113980409617, 0.03823092905906797, 0.0026714158504007124, 0.012822796081923419, 0.015969130305728704, 0.01757197981596913, 0.05520926090828139, 0.19133273968536657, 0.0010092015434847135, 0.1199168892846542, 0.004986642920747996, 0.0007123775601068567], \"num_examples\": 16845.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"bkr\", \"threshold\": 2.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.10980333730631704, 0.010354588796185936, 0.07896305125148986, 0.11568831942789035, 0.0007449344457687723, 0.00037246722288438616, 0.24337008343265792, 0.02152860548271752, 0.0005214541120381407, 0.006108462455303933, 0.0030542312276519664, 0.02026221692491061, 0.04261025029797378, 0.22199046483909415, 0.0, 0.12462753277711561, 0.0, 0.0], \"num_examples\": 13424.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"bkc\", \"mask\": [\"h\", \"a\", \"b\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.08613196365073093, 0.024693796918214144, 0.15507704464638483, 0.022718293164757014, 0.0019755037534571317, 0.0009877518767285659, 0.13453180561043065, 0.04780719083366258, 0.001382852627419992, 0.01382852627419992, 0.007111813512445673, 0.0007902015013828526, 0.08692216515211379, 0.21730541288028446, 0.0, 0.19873567759778743, 0.0, 0.0], \"num_examples\": 5062.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"wkr\", \"threshold\": 1.5}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.12413298254006219, 0.0016742406122937097, 0.03288686917005501, 0.17196842860559675, 0.0, 0.0, 0.30925615881368096, 0.005620664912700311, 0.0, 0.0014350633819660368, 0.000597943075819182, 0.032049748863908156, 0.015785697201626404, 0.22482659650801243, 0.0, 0.07976560631427888, 0.0, 0.0], \"num_examples\": 8362.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"wkr\", \"threshold\": 1.5}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.08623209587839813, 0.10143232972814967, 0.10143232972814967, 0.03595439929845075, 0.04501607717041801, 0.030692779888921367, 0.061385559777842734, 0.10377082724349605, 0.011107863197895352, 0.03916983338205203, 0.06664717918737212, 0.0070154925460391695, 0.10464776381175095, 0.0710318620286466, 0.004969307220111079, 0.10143232972814967, 0.024554223911137093, 0.0035077462730195848], \"num_examples\": 3421.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"bkc\", \"mask\": [\"h\", \"g\", \"f\", \"e\", \"d\", \"c\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.08914325355532432, 0.11238293444328824, 0.10267082899757198, 0.04266389177939646, 0.018383628165105793, 0.00693721817551162, 0.07075962539021852, 0.12105445716267776, 0.0, 0.03850156087408949, 0.07388137356919876, 0.008324661810613945, 0.12001387443635102, 0.08255289628858828, 0.0, 0.11272979535206382, 0.0, 0.0], \"num_examples\": 2883.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"wrr\", \"threshold\": 3.5}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.07063197026022305, 0.04275092936802974, 0.09479553903345725, 0.0, 0.18773234200743494, 0.1579925650557621, 0.011152416356877323, 0.011152416356877323, 0.07063197026022305, 0.04275092936802974, 0.027881040892193308, 0.0, 0.022304832713754646, 0.00929368029739777, 0.031598513011152414, 0.040892193308550186, 0.15613382899628253, 0.022304832713754646], \"num_examples\": 538.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"wkc\", \"mask\": [\"c\"]}}]}]}]}, \"#tree_plot_eb19abc8a79a46169f3381bcc46e41af\")\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfdf.model_plotter.plot_model_in_colab(model, tree_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b527dcd5-587b-4712-8dd6-7a9cd2cfb9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 0s 775us/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f9e6c5ac160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f9e6c5ac160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9e6c78a430>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all the other available learning algorithms\n",
    "# tfdf.keras.get_all_models()\n",
    "\n",
    "# ? tfdf.keras.GradientBoostedTreesModel\n",
    "\n",
    "\n",
    "# Create another model with specified hyper-parameters\n",
    "model = tfdf.keras.GradientBoostedTreesModel(\n",
    "    num_trees=500,\n",
    "    growing_strategy=\"BEST_FIRST_GLOBAL\",\n",
    "    max_depth=8,\n",
    "    split_axis=\"SPARSE_OBLIQUE\"\n",
    "    )\n",
    "model.fit(train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e6d74b0f-77a9-49f4-a74f-48e8a0c0ded9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 2s 24ms/step - loss: 0.0000e+00 - accuracy: 0.8886\n",
      "[0.0, 0.8886315226554871]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.compile(metrics=[\"accuracy\"])\n",
    "print(model.evaluate(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4e47f3dc-4aa9-4c52-9341-d222888a070a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtfdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientBoostedTreesModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Gradient Boosted Trees learning algorithm.\n",
       "\n",
       "A GBT (Gradient Boosted [Decision] Tree; https://statweb.stanford.edu/~jhf/ftp/trebst.pdf) is a set of shallow decision trees trained sequentially. Each tree is trained to predict and then \"correct\" for the errors of the previously trained trees (more precisely each tree predict the gradient of the loss relative to the model output).\n",
       "\n",
       "Usage example:\n",
       "\n",
       "```python\n",
       "import tensorflow_decision_forests as tfdf\n",
       "import pandas as pd\n",
       "\n",
       "dataset = pd.read_csv(\"project/dataset.csv\")\n",
       "tf_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(dataset, label=\"my_label\")\n",
       "\n",
       "model = tfdf.keras.GradientBoostedTreesModel()\n",
       "model.fit(tf_dataset)\n",
       "\n",
       "print(model.summary())\n",
       "```\n",
       "\n",
       "Attributes:\n",
       "  task: Task to solve (e.g. Task.CLASSIFICATION, Task.REGRESSION,\n",
       "    Task.RANKING).\n",
       "  features: Specify the list and semantic of the input features of the model.\n",
       "    If not specified, all the available features will be used. If specified\n",
       "    and if `exclude_non_specified_features=True`, only the features in\n",
       "    `features` will be used by the model. If \"preprocessing\" is used,\n",
       "    `features` corresponds to the output of the preprocessing. In this case,\n",
       "    it is recommended for the preprocessing to return a dictionary of tensors.\n",
       "  exclude_non_specified_features: If true, only use the features specified in\n",
       "    `features`.\n",
       "  preprocessing: Functional keras model or @tf.function to apply on the input\n",
       "    feature before the model to train. This preprocessing model can consume\n",
       "    and return tensors, list of tensors or dictionary of tensors. If\n",
       "    specified, the model only \"sees\" the output of the preprocessing (and not\n",
       "    the raw input). Can be used to prepare the features or to stack multiple\n",
       "    models on top of each other. Unlike preprocessing done in the tf.dataset,\n",
       "    the operation in \"preprocessing\" are serialized with the model.\n",
       "  ranking_group: Only for `task=Task.RANKING`. Name of a tf.string feature that\n",
       "    identifies queries in a query/document ranking task. The ranking group\n",
       "    is not added automatically for the set of features if\n",
       "    `exclude_non_specified_features=false`.\n",
       "  temp_directory: Temporary directory used during the training. The space\n",
       "    required depends on the learner. In many cases, only a temporary copy of a\n",
       "    model will be there.\n",
       "  verbose: If true, displays information about the training.\n",
       "  hyperparameter_template: Override the default value of the hyper-parameters.\n",
       "    If None (default) the default parameters of the library are used. If set,\n",
       "    `default_hyperparameter_template` refers to one of the following\n",
       "    preconfigured hyper-parameter sets. Those sets outperforms the default\n",
       "    hyper-parameters (either generally or in specific scenarios).\n",
       "    You can omit the version (e.g. remove \"@v5\") to use the last version of\n",
       "    the template. In this case, the hyper-parameter can change in between\n",
       "    releases (not recommended for training in production).\n",
       "  advanced_arguments: Advanced control of the model that most users won't need\n",
       "    to use. See `AdvancedArguments` for details.\n",
       "      - better_default@v1: A configuration that is generally better than the default parameters without being more expensive. The parameters are: growing_strategy=\"BEST_FIRST_GLOBAL\".\n",
       "      - benchmark_rank1@v1: Top ranking hyper-parameters on our benchmark slightly modified to run in reasonable time. The parameters are: growing_strategy=\"BEST_FIRST_GLOBAL\", categorical_algorithm=\"RANDOM\", split_axis=\"SPARSE_OBLIQUE\", sparse_oblique_normalization=\"MIN_MAX\", sparse_oblique_num_projections_exponent=1.0.\n",
       "\n",
       "  adapt_subsample_for_maximum_training_duration: Control how the maximum training duration (if set) is applied. If false, the training stop when the time is used. If true, the size of the sampled datasets used train individual trees are adapted dynamically so that all the trees are trained in time. Default: False.\n",
       "  allow_na_conditions: If true, the tree training evaluates conditions of the type `X is NA` i.e. `X is missing`. Default: False.\n",
       "  categorical_algorithm: How to learn splits on categorical attributes.\n",
       "    - `CART`: CART algorithm. Find categorical splits of the form \"value \\\\in mask\". The solution is exact for binary classification, regression and ranking. It is approximated for multi-class classification. This is a good first algorithm to use. In case of overfitting (very small dataset, large dictionary), the \"random\" algorithm is a good alternative.\n",
       "    - `ONE_HOT`: One-hot encoding. Find the optimal categorical split of the form \"attribute == param\". This method is similar (but more efficient) than converting converting each possible categorical value into a boolean feature. This method is available for comparison purpose and generally performs worse than other alternatives.\n",
       "    - `RANDOM`: Best splits among a set of random candidate. Find the a categorical split of the form \"value \\\\in mask\" using a random search. This solution can be seen as an approximation of the CART algorithm. This method is a strong alternative to CART. This algorithm is inspired from section \"5.1 Categorical Variables\" of \"Random Forest\", 2001. Default: \"CART\".\n",
       "  categorical_set_split_greedy_sampling: For categorical set splits e.g. texts. Probability for a categorical value to be a candidate for the positive set. The sampling is applied once per node (i.e. not at every step of the greedy optimization). Default: 0.1.\n",
       "  categorical_set_split_max_num_items: For categorical set splits e.g. texts. Maximum number of items (prior to the sampling). If more items are available, the least frequent items are ignored. Changing this value is similar to change the \"max_vocab_count\" before loading the dataset, with the following exception: With `max_vocab_count`, all the remaining items are grouped in a special Out-of-vocabulary item. With `max_num_items`, this is not the case. Default: -1.\n",
       "  categorical_set_split_min_item_frequency: For categorical set splits e.g. texts. Minimum number of occurrences of an item to be considered. Default: 1.\n",
       "  dart_dropout: Dropout rate applied when using the DART i.e. when forest_extraction=DART. Default: 0.01.\n",
       "  early_stopping: Early stopping detects the overfitting of the model and halts it training using the validation dataset controlled by `validation_ratio`.\n",
       "    - `NONE`: No early stopping. The model is trained entirely.\n",
       "    - `MIN_LOSS_FINAL`: No early stopping. However, the model is then truncated to maximize the validation loss.\n",
       "    - `LOSS_INCREASE`: Stop the training when the validation does not decrease for `early_stopping_num_trees_look_ahead` trees. Default: \"LOSS_INCREASE\".\n",
       "  early_stopping_num_trees_look_ahead: Rolling number of trees used to detect validation loss increase and trigger early stopping. Default: 30.\n",
       "  forest_extraction: How to construct the forest:\n",
       "    - MART: For Multiple Additive Regression Trees. The \"classical\" way to build a GBDT i.e. each tree tries to \"correct\" the mistakes of the previous trees.\n",
       "    - DART: For Dropout Additive Regression Trees. A modification of MART proposed in http://proceedings.mlr.press/v38/korlakaivinayak15.pdf. Here, each tree tries to \"correct\" the mistakes of a random subset of the previous trees. Default: \"MART\".\n",
       "  goss_alpha: Alpha parameter for the GOSS (Gradient-based One-Side Sampling; \"See LightGBM: A Highly Efficient Gradient Boosting Decision Tree\") sampling method. Default: 0.2.\n",
       "  goss_beta: Beta parameter for the GOSS (Gradient-based One-Side Sampling) sampling method. Default: 0.1.\n",
       "  growing_strategy: How to grow the tree.\n",
       "    - `LOCAL`: Each node is split independently of the other nodes. In other words, as long as a node satisfy the splits \"constraints (e.g. maximum depth, minimum number of observations), the node will be split. This is the \"classical\" way to grow decision trees.\n",
       "    - `BEST_FIRST_GLOBAL`: The node with the best loss reduction among all the nodes of the tree is selected for splitting. This method is also called \"best first\" or \"leaf-wise growth\". See \"Best-first decision tree learning\", Shi and \"Additive logistic regression : A statistical view of boosting\", Friedman for more details. Default: \"LOCAL\".\n",
       "  in_split_min_examples_check: Whether to check the `min_examples` constraint in the split search (i.e. splits leading to one child having less than `min_examples` examples are considered invalid) or before the split search (i.e. a node can be derived only if it contains more than `min_examples` examples). If false, there can be nodes with less than `min_examples` training examples. Default: True.\n",
       "  l1_regularization: L1 regularization applied to the training loss. Impact the tree structures and lead values. Default: 0.0.\n",
       "  l2_categorical_regularization: L2 regularization applied to the training loss for categorical features. Impact the tree structures and lead values. Default: 1.0.\n",
       "  l2_regularization: L2 regularization applied to the training loss for all features except the categorical ones. Default: 0.0.\n",
       "  lambda_loss: Lambda regularization applied to certain training loss functions. Only for NDCG loss. Default: 1.0.\n",
       "  max_depth: Maximum depth of the tree. `max_depth=1` means that all trees will be roots. Negative values are ignored. Default: 6.\n",
       "  max_num_nodes: Maximum number of nodes in the tree. Set to -1 to disable this limit. Only available for `growing_strategy=BEST_FIRST_GLOBAL`. Default: None.\n",
       "  maximum_training_duration_seconds: Maximum training duration of the model expressed in seconds. Each learning algorithm is free to use this parameter at it sees fit. Enabling maximum training duration makes the model training non-deterministic. Default: -1.0.\n",
       "  min_examples: Minimum number of examples in a node. Default: 5.\n",
       "  missing_value_policy: Method used to handle missing attribute values.\n",
       "    - `GLOBAL_IMPUTATION`: Missing attribute values are imputed, with the mean (in case of numerical attribute) or the most-frequent-item (in case of categorical attribute) computed on the entire dataset (i.e. the information contained in the data spec).\n",
       "    - `LOCAL_IMPUTATION`: Missing attribute values are imputed with the mean (numerical attribute) or most-frequent-item (in the case of categorical attribute) evaluated on the training examples in the current node.\n",
       "    - `RANDOM_LOCAL_IMPUTATION`: Missing attribute values are imputed from randomly sampled values from the training examples in the current node. This method was proposed by Clinic et al. in \"Random Survival Forests\" (https://projecteuclid.org/download/pdfview_1/euclid.aoas/1223908043). Default: \"GLOBAL_IMPUTATION\".\n",
       "  num_candidate_attributes: Number of unique valid attributes tested for each node. An attribute is valid if it has at least a valid split. If `num_candidate_attributes=0`, the value is set to the classical default value for Random Forest: `sqrt(number of input attributes)` in case of classification and `number_of_input_attributes / 3` in case of regression. If `num_candidate_attributes=-1`, all the attributes are tested. Default: -1.\n",
       "  num_candidate_attributes_ratio: Ratio of attributes tested at each node. If set, it is equivalent to `num_candidate_attributes = number_of_input_features x num_candidate_attributes_ratio`. The possible values are between ]0, and 1] as well as -1. If not set or equal to -1, the `num_candidate_attributes` is used. Default: -1.0.\n",
       "  num_trees: Maximum number of decision trees. The effective number of trained tree can be smaller if early stopping is enabled. Default: 300.\n",
       "  sampling_method: Control the sampling of the datasets used to train individual trees.\n",
       "    - NONE: No sampling is applied.\n",
       "    - RANDOM: Uniform random sampling. Automatically selected if \"subsample\" is set.\n",
       "    - GOSS: Gradient-based One-Side Sampling. Automatically selected if \"goss_alpha\" or \"goss_beta\" is set.\n",
       "    - SELGB: Selective Gradient Boosting. Automatically selected if \"selective_gradient_boosting_ratio\" is set.\n",
       "      Default: \"NONE\".\n",
       "  selective_gradient_boosting_ratio: Ratio of the dataset used to train individual tree for the selective Gradient Boosting (Selective Gradient Boosting for Effective Learning to Rank; Lucchese et al; http://quickrank.isti.cnr.it/selective-data/selective-SIGIR2018.pdf) sampling method. Default: 0.01.\n",
       "  shrinkage: Coefficient applied to each tree prediction. A small value (0.02) tends to give more accurate results (assuming enough trees are trained), but results in larger models. Analogous to neural network learning rate. Default: 0.1.\n",
       "  sparse_oblique_normalization: For sparse oblique splits i.e. `split_axis=SPARSE_OBLIQUE`. Normalization applied on the features, before applying the sparse oblique projections.\n",
       "    - `NONE`: No normalization.\n",
       "    - `STANDARD_DEVIATION`: Normalize the feature by the estimated standard deviation on the entire train dataset. Also known as Z-Score normalization.\n",
       "    - `MIN_MAX`: Normalize the feature by the range (i.e. max-min) estimated on the entire train dataset. Default: None.\n",
       "  sparse_oblique_num_projections_exponent: For sparse oblique splits i.e. `split_axis=SPARSE_OBLIQUE`. Controls of the number of random projections to test at each node as `num_features^num_projections_exponent`. Default: None.\n",
       "  sparse_oblique_projection_density_factor: For sparse oblique splits i.e. `split_axis=SPARSE_OBLIQUE`. Controls of the number of random projections to test at each node as `num_features^num_projections_exponent`. Default: None.\n",
       "  split_axis: What structure of split to consider for numerical features.\n",
       "    - `AXIS_ALIGNED`: Axis aligned splits (i.e. one condition at a time). This is the \"classical\" way to train a tree. Default value.\n",
       "    - `SPARSE_OBLIQUE`: Sparse oblique splits (i.e. splits one a small number of features) from \"Sparse Projection Oblique Random Forests\", Tomita et al., 2020. Default: \"AXIS_ALIGNED\".\n",
       "  subsample: Ratio of the dataset (sampling without replacement) used to train individual trees for the random sampling method. Default: 1.0.\n",
       "  use_hessian_gain: Use true, uses a formulation of split gain with a hessian term i.e. optimizes the splits to minimize the variance of \"gradient / hessian. Available for all losses except regression. Default: False.\n",
       "  validation_ratio: Ratio of the training dataset used to monitor the training. Require to be >0 if early stopping is enabled. Default: 0.1.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/tf2.5/lib/python3.8/site-packages/tensorflow_decision_forests/keras/__init__.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfdf.keras.GradientBoostedTreesModel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0bc498-818d-4466-887d-3cf717548611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.5",
   "language": "python",
   "name": "tf2.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
